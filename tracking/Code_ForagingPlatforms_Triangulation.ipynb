{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Script for: Continuous foraging behavior shapes patch-leaving decisions in pigeons: A 3D tracking study\n",
    "\n",
    "Guillermo Hidalgo Gadea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal foraging behavior is a key component of successful adaptations to natural environments. Understanding how animals decide to stay near food or to leave it for another food patch gives us insights into the underlying cognitive mechanisms that govern adaptive behaviors. 3D pose tracking was used to determine how pigeons exploit a 4 square meter arena with two separate platforms (i.e. food patches) whose absolute and relative elevations were manipulated. Detailed kinematic features of foraging and traveling behaviors were quantified using automated video tracking, without a need for manual coding. Our computational approach captured continuous, high-dimensional movement patterns and enabled precise quantification of travel costs between patches. Combined with mixed-effects survival analysis, our detailed behavioral tracking provided unprecedented insight into the moment-by-moment dynamics of patch-leaving decisions of pigeons. As expected from behavior optimization models, our results showed a preference to visit a ground food platform first, and longer latencies to leave an elevated platform. Foraging activity significantly decreased throughout a session, with shorter visits, less pecks per visit, and a decrease in inter-peck variability. However, a mixed-effects Cox regression modeled pigeons' patch-leaving probability, demonstrating that current and cumulative foraging parameters between patches significantly enhanced the model's predictive power beyond patch accessibility (i.e., beyond travel costs). This suggests that pigeons integrate both current environmental cues and their individual foraging history when making patch-leaving decisions. Our findings are discussed in relation to the marginal value theorem and optimal foraging theory.\n",
    "\n",
    "`updated 22.08.2025`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Triangulation Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages needed\n",
    "import os, sys\n",
    "import deeplabcut\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# load MotionPype\n",
    "from motionpype import utils, dlcspecifics, aniposespecific"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Video Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename calibration and reference videos from path\n",
    "calibration_path = r'G:\\ForagingPlatformsArena_local\\Calibration'\n",
    "reference_path = r'G:\\ForagingPlatformsArena_local\\Reference'\n",
    "projectname = 'ForagingPlatforms'\n",
    "extension = '.avi'\n",
    "rule1 = r'_|\\\\|/|.avi'\n",
    "rule2 = '202' #common in all dates from 2022 to 2023\n",
    "rule3 = 'P'\n",
    "cam_assignement = { '20323040': 'camA',\n",
    "                    '20323042': 'camB', \n",
    "                    '20323043': 'camC',\n",
    "                    '20323044': 'camD', \n",
    "                    '20323049': 'camE', \n",
    "                    '20323052': 'camF'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'calibration'\n",
    "raw_videos = utils.scrapdirbystring(calibration_path, extension, output=False)\n",
    "\n",
    "utils.batchrenamebyrules(raw_videos, calibration_path, extension, projectname, keyword, cam_assignement, rule1, rule2, rule3, rename = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'reference'\n",
    "raw_videos = utils.scrapdirbystring(reference_path, extension, output=False)\n",
    "\n",
    "utils.batchrenamebyrules(raw_videos, reference_path, extension, projectname, keyword, cam_assignement, rule1, rule2, rule3, rename = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new Anipose Project fro 3D Triangulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anipose Project created or updated: G:\\ForagingPlatformsArena_local\\Triangulation\n"
     ]
    }
   ],
   "source": [
    "# create new anipose project\n",
    "project_name = 'Triangulation'\n",
    "project_directory = r'G:\\ForagingPlatformsArena_local'\n",
    "# see nested structure in session_list with Pigeon IDs as trials nested in dated sessions\n",
    "session_list = [\n",
    "                '20221019/P393', '20221019/P430', '20221019/P434', '20221020/P195', '20221020/P437', '20221020/P600',\n",
    "                '20221021/P195', '20221021/P393', '20221021/P430', '20221021/P434', '20221021/P437', '20221021/P600',\n",
    "                '20221024/P195', '20221024/P393', '20221024/P430', '20221024/P434', '20221024/P437', '20221024/P600',\n",
    "                '20221025/P195', '20221025/P393', '20221025/P430', '20221025/P434', '20221025/P437', '20221025/P600', \n",
    "                '20221026/P195', '20221026/P393', '20221026/P430', '20221026/P434', '20221026/P437', '20221026/P600', \n",
    "                '20221027/P195', '20221027/P393', '20221027/P430', '20221027/P434', '20221027/P437', '20221027/P600', \n",
    "                '20221028/P195', '20221028/P393', '20221028/P430', '20221028/P434', '20221028/P437', '20221028/P600', \n",
    "                '20221031/P195', '20221031/P393', '20221031/P430', '20221031/P434', '20221031/P437', '20221031/P600', \n",
    "                '20221101/P195', '20221101/P393', '20221101/P430', '20221101/P434', '20221101/P437', '20221101/P600', \n",
    "                '20221102/P195', '20221102/P393', '20221102/P430', '20221102/P434', '20221102/P437', '20221102/P600', \n",
    "                '20221103/P195', '20221103/P393', '20221103/P430', '20221103/P434', '20221103/P437', '20221103/P600', \n",
    "                '20221104/P195', '20221104/P393', '20221104/P430', '20221104/P434', '20221104/P437', '20221104/P600', \n",
    "                '20230206/P122', '20230206/P204', '20230206/P428', '20230206/P436', '20230206/P589', '20230206/P791', \n",
    "                '20230207/P122', '20230207/P204', '20230207/P428', '20230207/P436', '20230207/P589', '20230207/P791', \n",
    "                '20230208/P122', '20230208/P204', '20230208/P428', '20230208/P436', '20230208/P589', '20230208/P791', \n",
    "                '20230209/P122', '20230209/P204', '20230209/P428', '20230209/P436', '20230209/P589', '20230209/P791', \n",
    "                '20230210/P122', '20230210/P204', '20230210/P428', '20230210/P436', '20230210/P589', '20230210/P791', \n",
    "                '20230213/P122', '20230213/P204', '20230213/P428', '20230213/P436', '20230213/P589', '20230213/P791', \n",
    "                '20230214/P122', '20230214/P204', '20230214/P428', '20230214/P436', '20230214/P589', '20230214/P791', \n",
    "                '20230215/P122', '20230215/P204', '20230215/P428', '20230215/P436', '20230215/P589', '20230215/P791', \n",
    "                '20230216/P122', '20230216/P204', '20230216/P428', '20230216/P436', '20230216/P589', '20230216/P791', \n",
    "                '20230217/P122', '20230217/P204', '20230217/P428', '20230217/P436', '20230217/P589', '20230217/P791', \n",
    "                '20230220/P122', '20230220/P204', '20230220/P428', '20230220/P436', '20230220/P589', '20230220/P791', \n",
    "                '20230221/P122', '20230221/P204', '20230221/P428', '20230221/P436', '20230221/P589', '20230221/P791', \n",
    "                ]\n",
    "# see reference_nesting = 1 because cameras were referenced and calibrated only once per session\n",
    "projectpath = aniposespecific.create_projectstructure(project_name, project_directory, session_list, reference_nesting=1, calibration_nesting=1, output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate project with videos from source paths\n",
    "\n",
    "behavior_path = r'G:\\ForagingPlatformsArena_local\\Behavior'\n",
    "calibration_path = r'G:\\ForagingPlatformsArena_local\\Calibration'\n",
    "reference_path = r'G:\\ForagingPlatformsArena_local\\Reference'\n",
    "\n",
    "aniposespecific.populate_project(projectpath, behavior_path, calibration_path, reference_path, separators = r'_|\\\\|/',copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a config.toml file\n",
    "config_path = aniposespecific.create_config(projectpath, output = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add DeepLabCut Models to the Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"G:\\ForagingPlatformsArena_local\\Triangulation\\DLC_RefModel_HexArena_resnet_50-PigeonSuperModel.com-2023-06-04\\videos\"\n",
      "Created \"G:\\ForagingPlatformsArena_local\\Triangulation\\DLC_RefModel_HexArena_resnet_50-PigeonSuperModel.com-2023-06-04\\labeled-data\"\n",
      "Created \"G:\\ForagingPlatformsArena_local\\Triangulation\\DLC_RefModel_HexArena_resnet_50-PigeonSuperModel.com-2023-06-04\\training-datasets\"\n",
      "Created \"G:\\ForagingPlatformsArena_local\\Triangulation\\DLC_RefModel_HexArena_resnet_50-PigeonSuperModel.com-2023-06-04\\dlc-models\"\n",
      "Copying the videos\n",
      "G:\\ForagingPlatformsArena_local\\Triangulation\\DLC_RefModel_HexArena_resnet_50-PigeonSuperModel.com-2023-06-04\\videos\\logo.mp4\n",
      "Generated \"G:\\ForagingPlatformsArena_local\\Triangulation\\DLC_RefModel_HexArena_resnet_50-PigeonSuperModel.com-2023-06-04\\config.yaml\"\n",
      "\n",
      "A new project with name DLC_RefModel_HexArena_resnet_50-PigeonSuperModel.com-2023-06-04 is created at G:\\ForagingPlatformsArena_local\\Triangulation and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n",
      "Dowloading weights...\n",
      "Downloading the model from the DeepLabCut server @Harvard -> Go Crimson!!! https://gitlab.ruhr-uni-bochum.de/hidalggc/3dposetrackingoffreelymovingpigeons/-/raw/main/models/DLC_RefModel_HexArena_resnet_50.tar.gz....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "177668096B [00:05, 34196312.54B/s]                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\ForagingPlatformsArena_local\\Triangulation\\DLC_RefModel_HexArena_resnet_50-PigeonSuperModel.com-2023-06-04\\dlc-models\\iteration-0\\DLC_RefModel_HexArena_resnet_50Jun4-trainset95shuffle1\\train\\pose_cfg.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# monkeypatch for pretrained DLC models (works only in DLC < v2.3)\n",
    "dlcspecifics.monkeypatch()\n",
    "\n",
    "# create dummy video\n",
    "projectpath = r'G:\\ForagingPlatformsArena_local\\Triangulation'\n",
    "os.chdir(projectpath)\n",
    "url = 'https://gitlab.ruhr-uni-bochum.de/hidalggc/3dposetrackingoffreelymovingpigeons/-/raw/main/models/PigeonSuperModel.png?inline=false'\n",
    "video_path = utils.create_dummy_videos(projectpath, url)\n",
    "\n",
    "# create pre-trained model for PigeonSuperModel\n",
    "beh_config_path, _ = deeplabcut.create_pretrained_project(\n",
    "    'DLC_PigeonSuperModel_effnet_b0',\n",
    "    'PigeonSuperModel.com',\n",
    "    [video_path],\n",
    "    videotype='mp4',\n",
    "    model='PigeonSuperModel_effnet_b0',\n",
    "    analyzevideo=False,\n",
    "    filtered=False,\n",
    "    createlabeledvideo=False,\n",
    "    copy_videos=True,)\n",
    "\n",
    "# create pre-trained model for Arena Reference\n",
    "ref_config_path, _ = deeplabcut.create_pretrained_project(\n",
    "    'DLC_RefModel_HexArena_resnet_50',\n",
    "    'PigeonSuperModel.com',\n",
    "    [video_path],\n",
    "    videotype='mp4',\n",
    "    model='RefModel_HexArena_resnet_50',\n",
    "    analyzevideo=False,\n",
    "    filtered=False,\n",
    "    createlabeledvideo=False,\n",
    "    copy_videos=True,)\n",
    "\n",
    "os.remove(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit DLC models for viterbi filter\n",
    "\n",
    "edit = {'num_outputs': 10} # this is relevant for viterbi filter\n",
    "deeplabcut.auxiliaryfunctions.edit_config(beh_config_path, edit);\n",
    "deeplabcut.auxiliaryfunctions.edit_config(ref_config_path, edit);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Anipose Project Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change config.toml\n",
    "edits = {\n",
    "    'motionpype': {\n",
    "        'ref_model_folder': os.path.dirname(ref_config_path),\n",
    "        'beh_model_folder': os.path.dirname(beh_config_path), \n",
    "        },\n",
    "    'nesting': 2,\n",
    "    }\n",
    "\n",
    "aniposespecific.change_toml(edits, config_path)\n",
    "\n",
    "# find local and remote anaconda\n",
    "aniposespecific.find_anaconda(config_path, directories = ['C:\\\\Users','C:\\\\ProgramData',], query = 'Anaconda3', overwrite = False, output = False)\n",
    "aniposespecific.find_anaconda(config_path, directories = [r\"\\\\compute.ikn.psy.rub.de\\\\C$\\\\ProgramData\",], query = 'Anaconda3', overwrite = False, output = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Video Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Behavior Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change model_folder, video_type, videos_raw\n",
    "videotype = aniposespecific.check_videotype(config_path, 'videos-raw')\n",
    "config = aniposespecific.read_config(config_path)\n",
    "settings = {\n",
    "    'video_extension': videotype,\n",
    "    'model_folder': config['motionpype']['beh_model_folder'],\n",
    "    'nesting': 2,\n",
    "    'pipeline': {\n",
    "        'videos_raw': 'videos-raw',\n",
    "        'calibration_videos': 'videos-cal',\n",
    "        'calibration_results': 'videos-cal',\n",
    "        'pose_2d': 'pose-2d',\n",
    "        'pose_2d_filter': 'pose-2d-filtered', # this needs to be different than the directory above\n",
    "        'pose_3d': 'pose-3d',\n",
    "        'pose_3d_filter': 'pose-3d-filtered',\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running anipose analyze on Breadnut...\n"
     ]
    }
   ],
   "source": [
    "# run anipose on independent thread\n",
    "aniposespecific.execute_anipose(settings, 'analyze', config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project active in G:\\ForagingPlatformsArena_local\\Triangulation\n",
      "Found 25 sessions and 25 trials\n",
      "Found {6} videos per calibration, with 25 out of 25 sessions already calibrated\n",
      "- average calibration error of 0.78\n",
      "- bootstraped 95%-CI [0.65 - 0.95]\n",
      "Found 438 videos, (292 % of expected with 6 cameras and 25 trials)\n",
      "Found {18, 6} number of behavior videos per trial\n",
      "Found 144 analyzed videos (32 % of all 438 videos)\n",
      "Found 80 triangulated trials (320 % of all 25 trials)\n"
     ]
    }
   ],
   "source": [
    "config_path = r\"G:\\ForagingPlatformsArena_local\\Triangulation\\config.toml\"\n",
    "aniposespecific.project_overview(config_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Reference Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change model_folder, video_type, videos_raw\n",
    "videotype = aniposespecific.check_videotype(config_path, 'videos-ref')\n",
    "config = aniposespecific.read_config(config_path)\n",
    "\n",
    "settings = {\n",
    "    'model_folder': config['motionpype']['ref_model_folder'],\n",
    "    'video_extension': videotype,\n",
    "    'nesting': 1, # change this to access session-wide reference videos\n",
    "    'pipeline': {\n",
    "        'videos_raw': 'videos-ref', # changed this to grab ref videos\n",
    "        'calibration_videos': 'videos-cal',\n",
    "        'calibration_results': 'videos-cal',\n",
    "        'pose_2d': 'videos-ref',\n",
    "        'pose_2d_filter': 'pose-2d-filtered',\n",
    "        'pose_3d': 'pose-3d',\n",
    "        'pose_3d_filter': 'pose-3d-filtered',\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running anipose analyze on Breadnut...\n"
     ]
    }
   ],
   "source": [
    "# run anipose on independent thread\n",
    "aniposespecific.execute_anipose(settings, 'analyze', config_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Migrate project to Server for higher CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning project: G:\\ForagingPlatformsArena_local\\Triangulation \n",
      " to remote path: D:\\UserData\\Guillermo\\ForagingPlatforms_Triangulation_server on \\\\compute.ikn.psy.rub.de\n"
     ]
    }
   ],
   "source": [
    "client = r\"\\\\compute.ikn.psy.rub.de\"\n",
    "dest_path = \"D$\\\\UserData\\\\Guillermo\\\\ForagingPlatforms_Triangulation_server\"\n",
    "aniposespecific.clone_anipose_project(config_path, client, dest_path, videos = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbi and Median Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change filer settings\n",
    "settings = {\n",
    "    'nesting': 1, # change this to 1 to grab ref videos\n",
    "    'pipeline': {\n",
    "        'videos_raw': 'videos-raw',\n",
    "        'calibration_videos': 'videos-cal',\n",
    "        'calibration_results': 'videos-cal',\n",
    "        'pose_2d': 'videos-ref', # change this to grab ref videos\n",
    "        'pose_2d_filter': 'videos-ref-filtered', # change this to grab ref videos\n",
    "        'pose_3d': 'pose-3d',\n",
    "        'pose_3d_filter': 'pose-3d-filtered',\n",
    "        },\n",
    "    'filter': {\n",
    "        'enabled': True, \n",
    "        'type': 'viterbi', \n",
    "        'score_threshold': 0, # disable tracking likelihood \n",
    "        'n_back': 10,\n",
    "        'offset_threshold': 50, \n",
    "        'multiprocessing': True\n",
    "        }, \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running anipose filter on Breadnut...\n"
     ]
    }
   ],
   "source": [
    "# run anipose on remote\n",
    "command = 'filter'\n",
    "aniposespecific.execute_anipose(settings, command, config_path, output = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change filer settings\n",
    "settings = {\n",
    "    'nesting': 2, # changed this to grab ref videos\n",
    "    'pipeline': {\n",
    "        'videos_raw': 'videos-raw',\n",
    "        'calibration_videos': 'videos-cal',\n",
    "        'calibration_results': 'videos-cal',\n",
    "        'pose_2d': 'pose-2d', # changed this to grab ref videos\n",
    "        'pose_2d_filter': 'pose-2d-filtered',\n",
    "        'pose_3d': 'pose-3d',\n",
    "        'pose_3d_filter': 'pose-3d-filtered',\n",
    "        },\n",
    "    'filter': {\n",
    "        'enabled': True, \n",
    "        'type': 'viterbi', \n",
    "        'score_threshold': 0, # tracking likelihood \n",
    "        'n_back': 10,\n",
    "        'offset_threshold': 50, \n",
    "        'multiprocessing': True\n",
    "        }, \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running anipose filter on compute-ikn.serverhosting.ruhr-uni-bochum.de...\n"
     ]
    }
   ],
   "source": [
    "# run anipose on remote\n",
    "command = 'filter'\n",
    "client = r'\\\\compute.ikn.psy.rub.de'\n",
    "aniposespecific.execute_anipose(settings, command, config_path, client, output = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Behavior and Reference Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling project from \\\\compute.ikn.psy.rub.de\\D$\\UserData\\Guillermo\\ForagingPlatforms_Triangulation_server \n",
      " to: G:\\ForagingPlatformsArena_local\\Triangulation\n"
     ]
    }
   ],
   "source": [
    "# pull progress from remote\n",
    "config_path = r\"G:\\ForagingPlatformsArena_local\\Triangulation\\config.toml\"\n",
    "aniposespecific.pull_cloned_project(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project active in G:\\ForagingPlatformsArena_local\\Triangulation\n",
      "Found 25 sessions and 144 trials\n",
      "Found {6} videos per calibration, with 25 out of 25 sessions already calibrated\n",
      "- average calibration error of 0.78\n",
      "- bootstraped 95%-CI [0.65 - 0.95]\n",
      "Found 732 videos, (84 % of expected with 6 cameras and 144 trials)\n",
      "Found {0, 6} number of behavior videos per trial\n",
      "Found 0 analyzed videos (0 % of all 732 videos)\n",
      "Found 56 triangulated trials (38 % of all 144 trials)\n"
     ]
    }
   ],
   "source": [
    "aniposespecific.project_overview(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change merging settings\n",
    "settings = {\n",
    "    'merge': {\n",
    "        'behavior': 'pose-2d-filtered', \n",
    "        'reference': 'ref-filtered', \n",
    "        'output':'pose-2d-merged', \n",
    "        'nesting': 1, # levels between behavior and reference\n",
    "        }, \n",
    "    'triangulation':{\n",
    "        'triangulate': True,\n",
    "        'cam_regex': \"_cam([A-Z])$\",\n",
    "        },\n",
    "    }\n",
    "aniposespecific.change_toml(settings, config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aniposespecific.merge_referenceframes(config_path, overwrite = True, output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Filter merged pose with median\n",
    "# change filer settings\n",
    "settings = {\n",
    "    'nesting': 2, # changed this to grab ref videos\n",
    "    'pipeline': {\n",
    "        'videos_raw': 'videos-raw',\n",
    "        'calibration_videos': 'videos-cal',\n",
    "        'calibration_results': 'videos-cal',\n",
    "        'pose_2d': 'pose-2d-merged', # grab merged poses to filter\n",
    "        'pose_2d_filter': 'pose-2d-merged-filtered',\n",
    "        'pose_3d': 'pose-3d',\n",
    "        'pose_3d_filter': 'pose-3d-filtered',\n",
    "        },\n",
    "    'filter': {\n",
    "        'enabled': True, \n",
    "        'type': 'medfilt', \n",
    "        'score_threshold': 0, # ignore tracking likelihood\n",
    "        'offset_threshold': 20, # pixel difference to overwrite TODO how big is the scale?\n",
    "        'medfilt': 15, # at 50Hz this is a 300ms filter window \n",
    "        'spline': True, # cubic interpolation\n",
    "        'multiprocessing': True\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running anipose filter on Breadnut...\n"
     ]
    }
   ],
   "source": [
    "aniposespecific.execute_anipose(settings, 'filter', config_path, output = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping files in G:\\ForagingPlatformsArena_local\\Triangulation returned list of size: 150\n"
     ]
    }
   ],
   "source": [
    "# Data verification\n",
    "projectpath = os.path.dirname(config_path)\n",
    "files = utils.scrapdirbystring(projectpath, 'videos-ref-filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    df = pd.read_hdf(file)\n",
    "    subset = [col for col in df.columns if 'cA' in col or 'cB' in col or 'cC' in col or 'cD' in col or 'cE' in col or 'cF' in col]\n",
    "    xcols = [col for col in subset if 'x' in col]\n",
    "    ycols = [col for col in subset if 'y' in col]\n",
    "    xref = df.loc[:,xcols]\n",
    "    yref = df.loc[:,ycols]\n",
    "    plt.scatter(xref, yref);\n",
    "    plt.scatter(xref.iloc[:,0], yref.iloc[:,0], color = 'red');\n",
    "    plt.ylim((1440,0))\n",
    "    plt.title(f'{file}')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrate Cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found multiple video extensions: toml\n"
     ]
    }
   ],
   "source": [
    "# edit calibration parameters and change video_type if necessary\n",
    "videotype = aniposespecific.check_videotype(projectpath, 'videos-cal')\n",
    "\n",
    "edits = {\n",
    "    'video_extension': videotype,\n",
    "    'pipeline': {\n",
    "        'videos_raw': 'videos-raw',\n",
    "        'calibration_videos': 'videos-cal',\n",
    "        'calibration_results': 'videos-cal',\n",
    "        'pose_2d': 'pose-2d-merged', # grab merged poses to filter\n",
    "        'pose_2d_filter': 'pose-2d-merged-filtered',\n",
    "        'pose_3d': 'pose-3d',\n",
    "        'pose_3d_filter': 'pose-3d-filtered',\n",
    "        },\n",
    "    'calibration': {\n",
    "        'board_type': 'charuco', \n",
    "        'board_size': [7, 7], \n",
    "        'board_marker_bits': 4, \n",
    "        'board_marker_dict_number': 50, \n",
    "        'board_marker_length': 49, \n",
    "        'board_square_side_length': 70, \n",
    "        'animal_calibration': False, \n",
    "        'calibration_init': None,\n",
    "        'fisheye': False,\n",
    "        }, \n",
    "    'manual_verification': {\n",
    "        'manually_verify': False,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running anipose calibrate on Breadnut...\n"
     ]
    }
   ],
   "source": [
    "# run anipose on independent thread\n",
    "aniposespecific.execute_anipose(edits, 'calibrate', config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO consider patching calibration errors\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triangulate Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual trick: upload only the pose-2d-merged-filtered data for the upper half of the project and start a triangulation process. Once started, upload the second half of the pose-2d-merged-filtered data and start a second parallel process. This assumes RAM and CPU ressources would suffice for two parallel instances..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning project: G:\\ForagingPlatformsArena_local\\Triangulation \n",
      " to remote path: D:\\UserData\\Guillermo\\ForagingPlatforms_Triangulation_server on \\\\compute.ikn.psy.rub.de\n"
     ]
    }
   ],
   "source": [
    "# move project to server\n",
    "client = r\"\\\\compute.ikn.psy.rub.de\"\n",
    "dest_path = \"D$\\\\UserData\\\\Guillermo\\\\ForagingPlatforms_Triangulation_server\"\n",
    "aniposespecific.clone_anipose_project(config_path, client, dest_path, videos = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete upper half on compute server\n",
    "\n",
    "# delete 3d poses on compute\n",
    "\n",
    "# start triangulation\n",
    "\n",
    "# clone again\n",
    "\n",
    "# delete 3d poses on compute\n",
    "\n",
    "# start second triangulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to specify what data to get (filtered or not, where to find the calibration, and the actual triangulation parameters\n",
    "settings = {\n",
    "    'pipeline': {\n",
    "        'videos_raw': 'videos-raw',\n",
    "        'calibration_videos': 'videos-cal',\n",
    "        'calibration_results': 'videos-cal',\n",
    "        'pose_2d': 'pose-2d-merged', # grab merged poses to filter\n",
    "        'pose_2d_filter': 'pose-2d-merged-filtered',\n",
    "        'pose_3d': 'pose-3d',\n",
    "        'pose_3d_filter': 'pose-3d-filtered',\n",
    "        },\n",
    "    'filter': {\n",
    "        'enabled': True, # enable this to point to 'pose_2d_filter'\n",
    "        }, \n",
    "    'triangulation': {\n",
    "        'triangulate': True, \n",
    "        'cam_regex': '_cam([A-Z])$', \n",
    "        'ransac': False, \n",
    "        'optim': True, \n",
    "        'axes': [['x', 'cB', 'cA'], ['y', 'cA', 'cE']],\n",
    "        'reference_point': 'cA', \n",
    "        'scale_smooth': 4,  # strength of temporal constraint\n",
    "        'scale_length': 2, # strength of spatial constraint\n",
    "        'reproj_error_threshold': 50, # in pixels, for robust triangulation\n",
    "        'score_threshold': 0, # ignore original tracking likelihood\n",
    "        'n_deriv_smooth': 1, # speed should be smooth\n",
    "        'constraints': [ # interconnected arena\n",
    "            ['cA', 'cB'], ['cB', 'cC'], ['cC', 'cD'], ['cD', 'cE'], ['cE', 'cF'], ['cF', 'cA'], \n",
    "            ['cA', 'cE'], ['cF', 'cD'], ['cE', 'cC'],['cD', 'cB'],['cC', 'cA'], ['cB', 'cF'],\n",
    "            ['cA', 'cD'], ['cB', 'cE'], ['cC', 'cF'], \n",
    "            ],\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running anipose triangulate on compute-ikn.serverhosting.ruhr-uni-bochum.de...\n"
     ]
    }
   ],
   "source": [
    "# run anipose on remote\n",
    "command = 'triangulate'\n",
    "client = r'\\\\compute.ikn.psy.rub.de'\n",
    "aniposespecific.execute_anipose(settings, command, config_path, client, output = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETA \n",
    "# 60 min GPU per camera at 17 its/s\n",
    "# 1 min GPU per ref camera\n",
    "# 15 min calibration per session\n",
    "# 1 min viterbi filter\n",
    "# 10 sec viterbi filter\n",
    "# 70 min merge total\n",
    "# 10 sec median filter\n",
    "# 50 min triangulating points at 900 its/s\n",
    "# 2-8h optimization (+200GB RAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling project from \\\\compute.ikn.psy.rub.de\\D$\\UserData\\Guillermo\\ForagingPlatforms_Triangulation_server \n",
      " to: G:\\ForagingPlatformsArena_local\\Triangulation\n"
     ]
    }
   ],
   "source": [
    "# pull progress from remote\n",
    "config_path = r\"G:\\ForagingPlatformsArena_local\\Triangulation\\config.toml\"\n",
    "aniposespecific.pull_cloned_project(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project active in G:\\ForagingPlatformsArena_local\\Triangulation\n",
      "Found 25 sessions and 144 trials\n",
      "Found {6} videos per calibration, with 25 out of 25 sessions already calibrated\n",
      "- average calibration error of 0.78\n",
      "- bootstraped 95%-CI [0.65 - 0.94]\n",
      "Found 732 videos, (84 % of expected with 6 cameras and 144 trials)\n",
      "Found {0, 6} number of behavior videos per trial\n",
      "Found 0 analyzed videos (0 % of all 732 videos)\n",
      "Found 122 triangulated trials (84 % of all 144 trials)\n"
     ]
    }
   ],
   "source": [
    "aniposespecific.project_overview(config_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anipose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
